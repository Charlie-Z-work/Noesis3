# ğŸ“ Noesis Architecture Overview

## ğŸ§  Overview

NoesisÂ³ is a modular multi-agent cognitive framework composed of three distinct agentsâ€”**Origin**, **Riin**, and **Vanta**â€”orchestrated by a central coordination system with shared memory and standardized task interfaces.

This document outlines the architectural principles, component roles, and communication flow among modules in the system.

---

## ğŸ—‚ï¸ Core Components

### 1. Agents

Each agent is an autonomous cognitive unit with its own logic, configuration, and behavior:

* `origin/`: Handles scientific reasoning, mathematical modeling, and academic writing tasks.
* `riin/`: Responsible for creative tasks such as lyric generation, artistic expression, and voice synthesis.
* `vanta/`: Focuses on data modeling, quantitative analysis, and risk-based decision making.

Each agent exposes a unified entrypoint `run_task(config: dict)`.

### 2. `core/`

Provides coordination logic for routing tasks, inter-agent calls, and shared services:

* `agent_dispatcher.py`: Directs tasks to the right agent based on task type.
* `config_loader.py`: Loads YAML-based agent-specific configurations.

### 3. `memory/`

Stores shared memory across agents. Can be abstracted to Redis, SQLite, or JSON. Unified access via `MemoryClient` interface.

### 4. `config/`

Contains YAML configuration files for each agent:

* `origin.yaml`, `riin.yaml`, `vanta.yaml`

Includes model settings, pipeline steps, and runtime options.

### 5. `tasks/`

Defines structured task schemas that agents can execute. Each task includes:

* task\_id
* associated agent
* description and expected behavior
* path to test case file

---

## ğŸ” Communication Flow

```
[ CLI / API ]
     â†“
 [ core/agent_dispatcher.py ]
     â†“
 [ agent_module.run_task() ]
     â†“
[ local core logic + model APIs ]
     â†“
[ optional: write to memory/, read config/, log result ]
```

---

## ğŸ§° Extensibility

* Add new agent: create new folder `agent_name/` with core + config + tasks
* Add new task: define YAML in `tasks/` and implement handler logic in agent
* Swap LLM backend: change model config in YAML and update dispatch logic
* External UI: connect via CLI or expose core as FastAPI endpoints

---

## ğŸ“Œ Example Use Case

A user sends a `scientific_brainstorm` task via CLI:

* `agent_dispatcher.py` maps to `origin`
* `origin.run_task()` loads config and handles the task
* Intermediate results may be saved to `memory/`
* Final output saved to `logs/origin/YYYYMMDD.json`

---

## ğŸ“„ Status

This architecture is currently implemented in modular skeletons and is evolving toward full runtime capability.

---

## ğŸ‘¤ Maintained by

Charlie Z Â· [github.com/Charlie-Z-work](https://github.com/Charlie-Z-work)
